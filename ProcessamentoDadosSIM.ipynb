{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adriano\\AppData\\Local\\Temp\\ipykernel_10144\\1270269123.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=';', encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m file_name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     82\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(csv_dir, file_name)\n\u001b[1;32m---> 83\u001b[0m     process_csv_file(file_path)\n",
      "Cell \u001b[1;32mIn [2], line 11\u001b[0m, in \u001b[0;36mprocess_csv_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_csv_file\u001b[39m(file_path):\n\u001b[0;32m     10\u001b[0m     \u001b[39m#Função para o processamento de arquivos CSV\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file_path, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m     df \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mDTOBITO\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDTNASC\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mIDADEMAE\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPARTO\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPESO\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mGESTACAO\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mESCMAEAGR1\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCODMUNOCOR\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRACACOR\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     13\u001b[0m     df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mDTNASC\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnotna()] \u001b[39m#pegando somente as linhas que tem valores que não são NaN\u001b[39;00m\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\UFMG - DOUTORADO\\Dados SIM - Natalidade\\venvsim39\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import csv\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "from sqlalchemy import text\n",
    "\n",
    "def process_csv_file(file_path):\n",
    "    #Função para o processamento de arquivos CSV\n",
    "    df = pd.read_csv(file_path, sep=';', encoding='latin-1')\n",
    "    df = df[['DTOBITO', 'DTNASC','IDADEMAE','PARTO','PESO','GESTACAO','ESCMAEAGR1','CODMUNOCOR', 'RACACOR']]\n",
    "    df = df[df['DTNASC'].notna()] #pegando somente as linhas que tem valores que não são NaN\n",
    "    df = df[df['DTOBITO'].notna()]\n",
    "    df['DTNASC'] = df['DTNASC'].astype(np.int64) # convertendo as datas para int64\n",
    "    df['DTOBITO'] = df['DTOBITO'].astype(np.int64)\n",
    "    df['DTNASC'] = pd.to_datetime(df['DTNASC'], exact=False, errors = 'coerce', format='%d%m%Y')\n",
    "    df['DTOBITO'] = pd.to_datetime(df['DTOBITO'], exact=False, errors = 'coerce', format='%d%m%Y')\n",
    "    #exact=false serve para evitar o erro de datas que não se aplicam no formato desejado\n",
    "    #erros = 'coerce' serve para evitar o armazenamento de nanosegundos armazenados no python que não seguem o padrão das datas.\n",
    "    # o format tem que ser no formato dos meus dados.\n",
    "    df['IDADE'] = df['DTOBITO'].sub(df['DTNASC'], axis=0) #subtracao dos campos data para pegar a idade em dias.\n",
    "    df['IDADE'] = df['IDADE'].dt.days #convert timedelta type to int ou float\n",
    "    df = df[df['IDADE'] <= 28 ] #selecionando somente linhas com idade menor ou igual a 28\n",
    "    df = df.drop(df.index[df['IDADE'] < 0]) #excluindo linhas com idade negativa\n",
    "    df = df.sort_values(['CODMUNOCOR'], ascending=[True]) #ordenando em ordem crescent os municipios\n",
    "    file_name = os.path.split(file_path)\n",
    "\n",
    "    df['CODMUNOCOR'] = df['CODMUNOCOR'].astype(str) #convertendo a coluna para string\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"11\") for i in df['CODMUNOCOR']],'RO',df['CODMUNOCOR']) #substituindo o municipio por regiao\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"12\") for i in df['CODMUNOCOR']],'AC',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"13\") for i in df['CODMUNOCOR']],'AM',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"14\") for i in df['CODMUNOCOR']],'RR',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"15\") for i in df['CODMUNOCOR']],'PA',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"16\") for i in df['CODMUNOCOR']],'AP',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"17\") for i in df['CODMUNOCOR']],'TO',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"21\") for i in df['CODMUNOCOR']],'MA',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"22\") for i in df['CODMUNOCOR']],'PI',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"23\") for i in df['CODMUNOCOR']],'CE',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"24\") for i in df['CODMUNOCOR']],'RN',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"25\") for i in df['CODMUNOCOR']],'PB',df['CODMUNOCOR']) \n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"26\") for i in df['CODMUNOCOR']],'PE',df['CODMUNOCOR']) \n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"27\") for i in df['CODMUNOCOR']],'AL',df['CODMUNOCOR']) \n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"28\") for i in df['CODMUNOCOR']],'SE',df['CODMUNOCOR']) \n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"29\") for i in df['CODMUNOCOR']],'BA',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"31\") for i in df['CODMUNOCOR']],'MG',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"32\") for i in df['CODMUNOCOR']],'ES',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"33\") for i in df['CODMUNOCOR']],'RJ',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"35\") for i in df['CODMUNOCOR']],'SP',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"41\") for i in df['CODMUNOCOR']],'PR',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"42\") for i in df['CODMUNOCOR']],'SC',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"43\") for i in df['CODMUNOCOR']],'RS',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"50\") for i in df['CODMUNOCOR']],'MS',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"51\") for i in df['CODMUNOCOR']],'MT',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"52\") for i in df['CODMUNOCOR']],'GO',df['CODMUNOCOR'])\n",
    "    df['CODMUNOCOR']=np.where([i.startswith(\"53\") for i in df['CODMUNOCOR']],'DF',df['CODMUNOCOR'])\n",
    "  \n",
    "    # salvando o arquivo excel.\n",
    "    df.to_excel(file_name[1]+\".xlsx\")\n",
    "    print('DataFrame is written to Excel File successfully.')\n",
    "    # Read Excel file\n",
    "    #xls_dir = 'D:/UFMG - DOUTORADO/Dados SIM - Natalidade/Dados SIM/'\n",
    "    #df = pd.read_excel('D:/UFMG - DOUTORADO/Dados SIM - Natalidade/venvsim39/'+file_name[1]+\".xlsx\")\n",
    "    #query1 = str(text(\"SELECT PARTO, COUNT(PARTO), CODMUNOCOR FROM df GROUP BY CODMUNOCOR, PARTO\"))\n",
    "    #print(type(query1))\n",
    "    #parto = sqldf(query1)\n",
    "    #query2 = str(text(\"SELECT GESTACAO, COUNT(GESTACAO), CODMUNOCOR FROM df GROUP BY CODMUNOCOR, GESTACAO\"))\n",
    "    #gestacao = sqldf(query2)\n",
    "    #query3 = str(\"SELECT ESCMAEAGR1, COUNT(ESCMAEAGR1), CODMUNOCOR FROM df GROUP BY CODMUNOCOR, ESCMAEAGR1\")\n",
    "    #escolaridade = sqldf(query3)\n",
    "    #parto.to_csv(file_name[1]+'_parto.csv', sep=';')\n",
    "    #gestacao.to_csv(file_name[1]+'_gestacao.csv', sep=';')\n",
    "    #escolaridade.to_csv(file_name[1]+'_escolaridade.csv', sep=';')\n",
    "    df['CODMUNOCOR'].value_counts().to_excel(\"obitos_x_estado\"+file_name[1]+\".xlsx\")\n",
    "\n",
    "# Diretório que contém os arquivos CSV\n",
    "csv_dir = 'D:/UFMG - DOUTORADO/Dados SIM - Natalidade/venvsim39/'\n",
    "\n",
    "# Loop para processar cada arquivo CSV no diretório\n",
    "for file_name in os.listdir(csv_dir):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_dir, file_name)\n",
    "        process_csv_file(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venvsim39': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d66df1f5ba377e5b7cc706075f57baa4a19f5ea3b3af068d3b6a1f1315ee4199"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
